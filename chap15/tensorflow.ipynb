{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import warnings\n",
    "import threading\n",
    "warnings.filterwarnings('ignore', '.*do not.*',)\n",
    "#input: A Tensor. Must be one of the following types: half, bfloat16, float32, float64. \n",
    "#Shape [batch, in_depth, in_height, in_width, in_channels].\n",
    "\n",
    "batch_size_input= 2\n",
    "learning_rate_input=0.0001 #학습률\n",
    "grad_clip_input=5 #do not touch\n",
    "decrease_learing_rate=0.8 #매 반복마다 학습률 감소비율\n",
    "num_epochs_input=1205     \n",
    "dataset_input=0\n",
    "\n",
    "output_number_input=9 # 질문이 있냐 없냐므로 2개\n",
    "output_temp=list()\n",
    "dropout_rate_input=0.1 #드랍아웃 확률임 \n",
    "width_input=80     #영상 가로 픽셀 개수\n",
    "lenth_input=40     #영상 세로 픽셀 개수\n",
    "depth_input=3      #하나의 픽셀에 차원 개수 열영상은 온도 1개므로 1차원, 일반 카메라는 픽셀당 RGB 3개값이므로 3차원\n",
    "file_input='.csv'\n",
    "restore_='result_test.csv'\n",
    "with tf.device('/cpu:0'):\n",
    "    class VideoDataset():\n",
    "        def __init__(self, filenames, timesteps=10):\n",
    "        \n",
    "            self.set_timesteps(timesteps)\n",
    "            self.temp_red=list()\n",
    "            self.temp_blue=list()\n",
    "            self.temp_green=list()\n",
    "            xs_0=list()\n",
    "            ys_0=list()\n",
    "            xs_0_=list()\n",
    "            ys_0_temp=list()\n",
    "            xs_0_temp=list()\n",
    "            #print(xs_0)\n",
    "            self.tr_xs = np.arange(36).reshape((2,3,3,2))\n",
    "            print(\"종우\",self.tr_xs.shape)\n",
    "            self.tr_ys = np.arange(40,290,1).reshape((2,5,5,5))\n",
    "\n",
    "        def set_timesteps(self, timesteps):\n",
    "            self.timesteps = timesteps\n",
    "            self.input_shape = [timesteps+1, 100, 200, 3] #이미지 개수\n",
    "            self.output_shape = [timesteps+1, 2] #출력 2개의 속력\n",
    "\n",
    "        @property\n",
    "        def train_count(self):\n",
    "            return len(self.tr_xs)\n",
    "\n",
    "        \n",
    "        def get_train_data(self, batch_size, nth):\n",
    "            \n",
    "            \n",
    "            return self.tr_xs, self.tr_ys\n",
    "\n",
    "        def shuffle_train_data(self, size):\n",
    "            np.random.seed(int(time.time()))\n",
    "            self.indices = np.arange(size)\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        def get_test_data(self):\n",
    "            #print(\"the number of data is \", self.te_xs.shape)\n",
    "            return self.te_xs, self.te_ys\n",
    "\n",
    "\n",
    "        def divide_data(self, xs, ys, tr_ratio=0.7):\n",
    "            data_count = len(xs)\n",
    "\n",
    "            tr_cnt = int(data_count * tr_ratio / 10) * 10\n",
    "            te_cnt = data_count - (tr_cnt)\n",
    "\n",
    "            tr_from, tr_to = 0, tr_cnt\n",
    "            te_from, te_to = tr_cnt, data_count\n",
    "            print(\"divide_data,data_count,tr_from,tr_to,te_to\",data_count,tr_from,tr_to,te_to)\n",
    "            self.tr_xs = xs[tr_from:tr_to]\n",
    "            self.tr_ys = ys[tr_from:tr_to]\n",
    "            self.te_xs = xs[te_from:te_to]\n",
    "            self.te_ys = ys[te_from:te_to]\n",
    "            #print(self.tr_xs, self.te_xs)\n",
    "            self.input_shape = xs[0].shape\n",
    "            self.output_shape = ys[0].shape\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    class ConvNN(object):\n",
    "        def __init__(self, batchsize=batch_size_input,\n",
    "                 epochs=num_epochs_input, learning_rate=learning_rate_input, \n",
    "                 dropout_rate=dropout_rate_input, width=width_input, lenth=lenth_input, depth=depth_input,\n",
    "                 output_number=output_number_input,dataset=dataset_input,\n",
    "                  random_seed=None):\n",
    "            np.random.seed(int(time.time()))\n",
    "            self.batchsize = batchsize\n",
    "            self.epochs = epochs\n",
    "            self.learning_rate = learning_rate\n",
    "            self.dropout_rate = dropout_rate\n",
    "            self.dataset=dataset\n",
    "            self.width=width_input\n",
    "            self.length=lenth_input\n",
    "            self.depth=depth_input\n",
    "            self.output_number= output_number\n",
    "                \n",
    "            g = tf.Graph()\n",
    "            with g.as_default():\n",
    "            ## set random-seed:\n",
    "                tf.set_random_seed(random_seed)\n",
    "            \n",
    "            ## build the network:\n",
    "                self.build()\n",
    "\n",
    "            ## initializer\n",
    "                self.init_op = tf.global_variables_initializer()\n",
    "\n",
    "            ## saver\n",
    "                self.saver = tf.train.Saver()\n",
    "            \n",
    "        ## create a session\n",
    "            self.sess = tf.Session(graph=g)\n",
    "        def batch_generator(self,predict=False): #데이터 전처리용\n",
    "\n",
    "\n",
    "           \n",
    "            \n",
    "            return self.dataset.tr_xs,self.dataset.tr_ys\n",
    "\n",
    "        def target_batch_generator(self,predict=True):\n",
    "            X=self.dataset.te_xs\n",
    "            Y=self.dataset.te_ys\n",
    "            return X, Y       \n",
    "        def build(self):\n",
    "        \n",
    "        ## Placeholders for X and y:\n",
    "            tf_x = tf.placeholder(tf.float32, \n",
    "                              shape=[2,3,3,2],\n",
    "                              name='tf_x')\n",
    "            tf_y = tf.placeholder(tf.float32, \n",
    "                              shape=[2,5,5,5],\n",
    "                              name='tf_y')\n",
    "            is_train = tf.placeholder(tf.bool, \n",
    "                              shape=(),\n",
    "                              name='is_train')\n",
    "        \n",
    "            #print(tf_x)\n",
    "            #print(tf_y)\n",
    "\n",
    "            self.h1 = tf.layers.conv2d_transpose(inputs=tf_x,filters=5,\n",
    "                              kernel_size=(3, 3), strides=(1,1) ,\n",
    "                               kernel_initializer=tf.random_normal_initializer(mean=0,stddev=0.03),\n",
    "                              activation=None,name='h1')\n",
    "            \n",
    "            #print(self.h1.eval())\n",
    "         \n",
    "        \n",
    "        \n",
    "        ## Loss Function and Optimization\n",
    "            cost =tf.reduce_mean(tf.losses.mean_squared_error(\n",
    "                 labels=tf_y, predictions=self.h1), name='cost')\n",
    "            print(cost)\n",
    "        \n",
    "        ## Optimizer:\n",
    "            optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            train_op = optimizer.minimize(cost,name='train_op')\n",
    "            print(train_op)\n",
    "       \n",
    "\n",
    "        def save(self, epoch, path='./tflayers-model/'):\n",
    "            if not os.path.isdir(path):\n",
    "                os.makedirs(path)\n",
    "            print('Saving model in %s' % path)\n",
    "            self.saver.save(self.sess, \n",
    "                        os.path.join(path, 'model.ckpt'),\n",
    "                        global_step=epoch)\n",
    "        \n",
    "        def load(self, epoch, path):\n",
    "            print('Loading model from %s' % path)\n",
    "            self.saver.restore(self.sess, \n",
    "             os.path.join(path, 'model.ckpt-%d' % epoch))\n",
    "        \n",
    "        def train(self, ckpt_dir='model_2/', \n",
    "              initialize=True):\n",
    "        ## initialize variables\n",
    "           \n",
    "            ckpt_dir='./'+ckpt_dir+'/'\n",
    "            start = time.time()\n",
    "            if not os.path.exists(ckpt_dir):\n",
    "                os.mkdir(ckpt_dir)\n",
    "            if initialize:\n",
    "                self.sess.run(self.init_op)\n",
    "            \n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "             \n",
    "                batch_x,batch_y = self.batch_generator()\n",
    "  \n",
    "                self.learning_rate=decrease_learing_rate*self.learning_rate\n",
    "                \n",
    "                avg_loss = 0.0\n",
    "                print(batch_x.shape)\n",
    "                feed = {'tf_x:0': batch_x, \n",
    "                    'tf_y:0': batch_y,\n",
    "                    'is_train:0': True} ## for dropout\n",
    "                output_=self.sess.run(['h1'], \n",
    "                    feed_dict={'tf_x:0': batch_x})\n",
    "                print(output_.eval())\n",
    "                loss, _ = self.sess.run(\n",
    "                    ['cost:0', 'train_op'], \n",
    "                    feed_dict=feed)\n",
    "                print(self.h1.eval())\n",
    "                print(batch_x)\n",
    "                self.saver.save(self.sess,ckpt_dir+\"image-%d.ckpt\" % epoch)\n",
    "                with open(restore_,'a',newline='') as aa:\n",
    "                    writer = csv.writer(aa, delimiter=',')\n",
    "                    avg_loss = loss\n",
    "                    ttt=self.predict_in()\n",
    "                    writer.writerow([epoch+1]+[i]+[np.mean(avg_loss)]+[ttt])\n",
    "\n",
    "                print('epoch ',epoch,'i ' ,i,'avg_loss ', avg_loss,\"test_loss\",ttt)\n",
    "       \n",
    "            \n",
    "                    \n",
    "        def predict(self, X_test, return_proba = False):\n",
    "            feed = {'tf_x:0': X_test,\n",
    "                'is_train:0': False} ## for dropout\n",
    "            if return_proba:\n",
    "                return self.sess.run('probabilities:0',\n",
    "                                 feed_dict=feed)\n",
    "            else:\n",
    "                return self.sess.run('labels:0',\n",
    "                                 feed_dict=feed)\n",
    "        \n",
    "        def predict_in(self, ckpt='./f_ma_original_/',initialize=False):\n",
    "    \n",
    "            \n",
    "            self.saver.restore(self.sess, tf.train.latest_checkpoint(ckpt))\n",
    "                \n",
    "                \n",
    "            batch_x, batch_y = self.target_batch_generator(predict=True)\n",
    "            pred_list=list()\n",
    "            batch_y_list=list()\n",
    "            \n",
    "                        \n",
    "                  \n",
    "            feed = {'tf_x:0': batch_x, \n",
    "                    'tf_y:0': batch_y,\n",
    "                    'is_train:0': False} ## for dropout\n",
    "            pred = self.sess.run([self.h5],feed_dict=feed)\n",
    "\n",
    "            \n",
    "                \n",
    "            diff = batch_y- pred\n",
    "            #print(\"diff.shape\",diff.shape)\n",
    "            square = np.square(diff)\n",
    "            loss = np.mean(square[:,:])    \n",
    "            return loss\n",
    "        \n",
    "  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    vsd  = VideoDataset(['physical_intution'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    \n",
    "   \n",
    "    cnn=ConvNN(dataset=vsd) #CNN 모델 클래스 하나 생성\n",
    "\n",
    "    cnn.train(ckpt_dir='f_ma_original_') #학습시켜서 ckpt_dir 에다가 기록해라"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
