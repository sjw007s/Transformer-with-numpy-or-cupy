{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../chap14/encoder_decoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gan(RnnExtModel):\n",
    "    #self.trans_jongwoo=1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_init_parameters(self, hconfigs):\n",
    "    gconf = hconfigs['generator']\n",
    "    dconf = hconfigs['discriminor']\n",
    "    \n",
    "    self.g_hconfigs = gconf\n",
    "    self.d_hconfigs = dconf\n",
    "    if not isinstance(gconf[0], list): gconf = [gconf]\n",
    "    if not isinstance(dconf[0], list): dconf = [dconf]\n",
    "        \n",
    "    self.seed_shape = hconfigs['seed_shape']\n",
    "    input_shape = self.dataset.input_shape\n",
    "\n",
    "    pmg, gen_shape = self.build_subnet(gconf, self.seed_shape)\n",
    "    pmd, bin_shape = self.build_subnet(dconf, input_shape)\n",
    "    print(input_shape)\n",
    "    print(gen_shape)\n",
    "    #assert tuple(gen_shape) == tuple(input_shape)\n",
    "    #assert tuple(bin_shape) == tuple([1])\n",
    "    \n",
    "    self.gconfigs, self.dconfigs = gconf, dconf\n",
    "    self.pm_gen, self.pm_dis = pmg, pmd\n",
    "\n",
    "    self.seqout = False\n",
    "    self.pm_output = None\n",
    "    \n",
    "Gan.build_subnet = autoencoder_build_subnet\n",
    "Gan.init_parameters = gan_init_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Gan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2fd2ae519640>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mGan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan_train_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Gan' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\"\"\"\n",
    "def gan_train_step(self, x, y):\n",
    "    self.is_training = True\n",
    "    #print(\"gan_train\")\n",
    "    #if self.epoch>500:\n",
    "    #    self.learning_rate=self.learning_rate*0.999\n",
    "    #print(\"22\",temp_1[0,0,:,0])\n",
    "    #output, aux_dis = self.forward_discriminor(temp_1)\n",
    "    #print(\"3\",output)\n",
    "    #fake_x, aux_gen = self.forward_generator(self.batch_size)\n",
    "    #g_loss, _ = self.forward_postproc(fake_x,x)\n",
    "    #print(g_loss)\n",
    "    #if self.epoch %5==0 or self.epoch <2:\n",
    "    d_loss = self.train_discriminor(x)\n",
    "    #    g_loss=0\n",
    "    #else:\n",
    "    #g_loss = self.train_generator(self.batch_size, x)\n",
    "    #g_loss = self.train_generator(self.batch_size, x)\n",
    "    #g_loss = self.train_generator(self.batch_size, x)\n",
    "    #g_loss = self.train_generator(self.batch_size)\n",
    "    #g_loss = self.train_generator(self.batch_size)\n",
    "    #g_loss = self.train_generator(self.batch_size)\n",
    "    g_loss = self.train_generator(self.batch_size)\n",
    "    \n",
    "    \n",
    "    #    d_loss=0\n",
    "    #for i in range(15):\n",
    "        #print(i,distance.euclidean(np_cpu.array(list(np.squeeze(temp_1[i,:]).reshape(900)))\\\n",
    "                                  # ,np_cpu.array(list(np.squeeze(temp_2[i,:]).reshape(900)))))\n",
    "        #print(i,distance.cosine(np_cpu.array(list(np.squeeze(temp_1[i,:]).reshape(900)))\\\n",
    "           #                        ,np_cpu.array(list(np.squeeze(temp_2[i,:]).reshape(900)))))\n",
    "    #for i in range(15):\n",
    "        #print(i+15,distance.euclidean(np_cpu.array(list(np.squeeze(x[i,:]).reshape(900)))\\\n",
    "                                    #  ,np_cpu.array(list(np.squeeze(temp_2[i,:]).reshape(900)))))\n",
    "        #print(i+15,distance.cosine(np_cpu.array(list(np.squeeze(x[i,:]).reshape(900)))\\\n",
    "                           #           ,np_cpu.array(list(np.squeeze(temp_2[i,:]).reshape(900)))))\n",
    "    #print(temp_1[0])\n",
    "    #print(\"dfsdfsdf\",x[0,])\n",
    "  \n",
    "    for i in range(20):\n",
    "        if (self.epoch % 2 == 0):\n",
    "        #if (1 == 0):    \n",
    "            d_loss =self.train_discriminor(x)\n",
    "            \n",
    "            #d_loss,_=self.train_discriminor(x)\n",
    "        else:\n",
    "            #self.learning_rate*=10\n",
    "            g_loss = self.train_generator(self.batch_size)\n",
    "            #self.learning_rate/=10\n",
    "            #g_loss,_=self.train_generator(self.batch_size)\n",
    "    \n",
    "    self.is_training = False\n",
    "    \n",
    "    return [d_loss, g_loss], 0\n",
    "\n",
    "Gan.train_step = gan_train_step\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_train_discriminor(self, real_x):\n",
    "    mb_size = self.batch_size\n",
    "    self.is_training = False\n",
    "    fake_x, _ = self.forward_generator(mb_size)\n",
    "    self.is_training = True\n",
    "    \"\"\"\n",
    "    if self.epoch == 0:\n",
    "        #print(fake_x.shape)\n",
    "        self.temp_fake=fake_x[0,:]\n",
    "        self.temp_fake=self.temp_fake[np.newaxis,:,:,:]\n",
    "        #print(\"1\",self.temp_fake.shape)\n",
    "    elif self.temp_fake.shape[0] <mb_size:\n",
    "        self.temp_temp_fake=fake_x[0]\n",
    "        self.temp_temp_fake=self.temp_temp_fake[np.newaxis,:,:,:]\n",
    "        #print(\"3\",self.temp_temp_fake.shape)\n",
    "        fake_x=np.vstack([self.temp_fake,fake_x[self.temp_fake.shape[0]:]])\n",
    "        #print(fake_x.shape)\n",
    "        #print(\"2\",fake_x.shape)\n",
    "        \n",
    "        #print(self.temp_fake.shape,fake_x[-1].shape)\n",
    "        self.temp_fake=np.vstack([self.temp_fake,self.temp_temp_fake])\n",
    "        #print(\"4\",self.temp_fake.shape)\n",
    "    else:\n",
    "        fake_x_tt=fake_x[0]\n",
    "        fake_x_tt=fake_x_tt[np.newaxis,:,:,:]\n",
    "        \n",
    "        fake_x=np.vstack([self.temp_fake[1:],fake_x_tt])\n",
    "    \"\"\"\n",
    "    #print(real_x.shape,fake_x.shape)\n",
    "    #print(real_x.shape,fake_x.shape)\n",
    "    #mixed_x = np.vstack([real_x, fake_x])\n",
    "    #print(\"mixed_x\",mixed_x.shape,fake_x.shape,real_x.shape)\n",
    "    #print(real_x.shape,fake_x.shape,mixed_x.shape)\n",
    "    \n",
    "    output, aux_dis = self.forward_discriminor(real_x)\n",
    "    #if self.n==9:\n",
    "    #    print(\"dicri\")\n",
    "    #    print(output)\n",
    "    #print(\"fake_x\")\n",
    "    #output, aux_dis = self.forward_discriminor(fake_x)\n",
    "    #print(\"1\",output)\n",
    "    #output, aux_dis = self.forward_discriminor(mixed_x)\n",
    "    #print(\"discriminor\")\n",
    "    #print(output)\n",
    "    y = np.ones([mb_size, 1], dtype = 'float32')\n",
    "    #y[0:mb_size, 0] = 1\n",
    " \n",
    "    \n",
    "    d_loss_1, aux_pp = self.forward_postproc(output, y)\n",
    "    #print(\"11\",fake_x[0,0,:,0])\n",
    "    G_loss = 1.0\n",
    "    G_output = self.backprop_postproc(G_loss, aux_pp)\n",
    "    self.backprop_discriminor(G_output, aux_dis)\n",
    "    \n",
    "    \n",
    "    output, aux_dis = self.forward_discriminor(fake_x)\n",
    "    #if self.n==9:\n",
    "    #    print(\"dicri\")\n",
    "    #    print(output)\n",
    "    #print(\"fake_x\")\n",
    "    #output, aux_dis = self.forward_discriminor(fake_x)\n",
    "    #print(\"1\",output)\n",
    "    #output, aux_dis = self.forward_discriminor(mixed_x)\n",
    "    #print(\"discriminor\")\n",
    "    #print(output)\n",
    "    y = np.zeros([mb_size, 1], dtype = 'float32')\n",
    "    #y[0:mb_size, 0] = 1\n",
    " \n",
    "    \n",
    "    d_loss_2, aux_pp = self.forward_postproc(output, y)\n",
    "    #print(\"11\",fake_x[0,0,:,0])\n",
    "    G_loss = 1.0\n",
    "    G_output = self.backprop_postproc(G_loss, aux_pp)\n",
    "    self.backprop_discriminor(G_output, aux_dis)\n",
    "    self.is_training = False\n",
    "    d_loss=(d_loss_1+d_loss_2)/2\n",
    "    return d_loss\n",
    "\n",
    "Gan.train_discriminor= gan_train_discriminor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_train_generator(self, mb_size):\n",
    "    \"\"\"\n",
    "    fake_x, aux_gen = self.forward_generator(mb_size)\n",
    "    #output, aux_dis = self.forward_discriminor(fake_x_x)\n",
    "    #print(\"3\",output)\n",
    "    mixed_x = np.vstack([fake_x,real])\n",
    "    output, aux_dis = self.forward_discriminor(mixed_x)\n",
    "    y = np.zeros([2*mb_size, 1], dtype = 'float32')\n",
    "    y[0:mb_size, 0] = 1\n",
    "    #print(\"solo\")\n",
    "    #print(output)\n",
    "    #output_, aux_dis_ = self.forward_discriminor(dis_fake_x)\n",
    "    #print(\"dual\")\n",
    "    #print(output_)\n",
    "    g_loss, aux_pp = self.forward_postproc(output, y)\n",
    "\n",
    "    G_loss = 1.0\n",
    "    G_output = self.backprop_postproc(G_loss, aux_pp)\n",
    "\n",
    "    self.is_training = False\n",
    "    G_fake_x = self.backprop_discriminor(G_output, aux_dis)\n",
    "    self.is_training = True\n",
    "    self.backprop_generator(G_fake_x[0:mb_size], aux_gen)\n",
    "    \"\"\"\n",
    "    self.is_training = True\n",
    "    fake_x, aux_gen = self.forward_generator(mb_size)\n",
    "    #output, aux_dis = self.forward_discriminor(fake_x_x)\n",
    "    #print(\"3\",output)\n",
    "    #mixed_x = np.vstack([fake_x,real])\n",
    "    self.is_training = False\n",
    "    output, aux_dis = self.forward_discriminor(fake_x)\n",
    "    y = np.ones([mb_size, 1], dtype = 'float32')\n",
    "    #y[0:mb_size, 0] = 1\n",
    "    #if self.n==9:\n",
    "    #    print(\"output\")\n",
    "    #    print(output)\n",
    "    #output_, aux_dis_ = self.forward_discriminor(dis_fake_x)\n",
    "    #print(\"dual\")\n",
    "    #print(output_)\n",
    "    g_loss, aux_pp = self.forward_postproc(output, y)\n",
    "\n",
    "    G_loss = 1.0\n",
    "    G_output = self.backprop_postproc(G_loss, aux_pp)\n",
    "\n",
    "    \n",
    "    G_fake_x = self.backprop_discriminor(G_output, aux_dis)\n",
    "    self.is_training = True\n",
    "    self.backprop_generator(G_fake_x, aux_gen)\n",
    "    self.is_training = False\n",
    "    return g_loss\n",
    "\n",
    "Gan.train_generator = gan_train_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_forward_discriminor(self, x):\n",
    "    hidden = x\n",
    "    aux_dis = []\n",
    "    #print(\"악\")\n",
    "    #print(hidden.shape)\n",
    "    for n, hconfig in enumerate(self.dconfigs):\n",
    "        #print(n)\n",
    "        hidden, aux = self.forward_layer(hidden, hconfig, self.pm_dis[n])\n",
    "        aux_dis.append(aux)\n",
    "        #print(\"악\")\n",
    "        #print(hidden.shape)\n",
    "        \n",
    "\n",
    "    return hidden, aux_dis\n",
    "\n",
    "def gan_backprop_discriminor(self, G_hidden, aux_dis):\n",
    "    for n in reversed(range(len(self.dconfigs))):\n",
    "        hconfig, pm, aux = self.dconfigs[n], self.pm_dis[n], aux_dis[n]\n",
    "        G_hidden = self.backprop_layer(G_hidden, hconfig, pm, aux)\n",
    "    return G_hidden\n",
    "\n",
    "\n",
    "Gan.forward_discriminor = gan_forward_discriminor\n",
    "Gan.backprop_discriminor = gan_backprop_discriminor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_forward_generator(self, mb_size):\n",
    "    #print(10000000*time.time())\n",
    "    #np.random.seed(int(10000000*time.time()))\n",
    "    np.random.seed(int(time.time()))\n",
    "    hidden = np.random.uniform(0,1, size=[mb_size]+self.seed_shape).astype(np.float32)\n",
    "    #print(\"tttt\",hidden)\n",
    "    aux_gen = []\n",
    "\n",
    "    for n, hconfig in enumerate(self.gconfigs):\n",
    "        hidden, aux = self.forward_layer(hidden, hconfig, self.pm_gen[n])\n",
    "        #print(n)\n",
    "        #print(hidden)\n",
    "        #for i in aux:\n",
    "            #print(type(i))\n",
    "            #pass\n",
    "        aux_gen.append(aux)\n",
    "    \n",
    "    return hidden, aux_gen\n",
    "\n",
    "def gan_backprop_generator(self, G_hidden, aux_gen):\n",
    "    for n in reversed(range(len(self.gconfigs))):\n",
    "        hconfig, pm, aux = self.gconfigs[n], self.pm_gen[n], aux_gen[n]\n",
    "        G_hidden = self.backprop_layer(G_hidden, hconfig, pm, aux)\n",
    "    return G_hidden\n",
    "\n",
    "Gan.forward_generator = gan_forward_generator\n",
    "Gan.backprop_generator = gan_backprop_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_update_param(self, pm, key, G_key):\n",
    "    if not self.is_training: return\n",
    "        \n",
    "    super(Gan, self).update_param(pm, key, G_key)\n",
    "    \n",
    "Gan.update_param = gan_update_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_eval_accuracy(self, real_x, y, output=None):\n",
    "    mb_size = len(real_x)\n",
    "\n",
    "    fake_x, _ = self.forward_generator(mb_size)\n",
    "    mixed_x = np.vstack([real_x, fake_x])\n",
    "    output, aux_dis = self.forward_discriminor(mixed_x)\n",
    "\n",
    "    y = np.zeros([2*mb_size, 1], dtype = 'float32')\n",
    "    y[0:mb_size] = 1.0\n",
    "    d_acc = self.dataset.eval_accuracy(mixed_x, y, output)\n",
    "    \n",
    "    fake_x, _ = self.forward_generator(mb_size)\n",
    "    output, aux_dis = self.forward_discriminor(fake_x)\n",
    "\n",
    "    y = np.ones([mb_size, 1], dtype = 'float32')\n",
    "    g_acc = self.dataset.eval_accuracy(fake_x, y, output)\n",
    "    \n",
    "    return [d_acc, g_acc]\n",
    "\n",
    "Gan.eval_accuracy = gan_eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_visualize(self, num):\n",
    "    real_x, _ = self.dataset.get_visualize_data(num)\n",
    "    fake_x, _ = self.forward_generator(num)\n",
    "    self.dataset.visualize(np.vstack([real_x,fake_x]))\n",
    "\n",
    "Gan.visualize = gan_visualize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
