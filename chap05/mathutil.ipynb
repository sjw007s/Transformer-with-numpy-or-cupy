{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as np\n",
    "#import numpy as np\n",
    "import numpy as np_cpu\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import copy    # chap 9\n",
    "import wave    # chap 11\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.core.display import HTML # chap 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def relu_derv(y):\n",
    "    return np.sign(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return np.maximum(x, 0.01*x)\n",
    "\n",
    "def leaky_relu_derv(y):\n",
    "    return np.where(y<0,0.01,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1.0 + np.exp(-x))\n",
    "        \n",
    "def sigmoid_derv(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "def sigmoid_cross_entropy_with_logits(z, x):\n",
    "    return x - x * z + np.log(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_cross_entropy_with_logits_derv(z, x):\n",
    "    return -z + sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return 2 * sigmoid(2*x) - 1\n",
    "\n",
    "def tanh_derv(y):\n",
    "    return (1.0 + y) * (1.0 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \n",
    "    max_elem = np.max(x, axis=1)\n",
    "    \n",
    "    diff = (x.transpose()-max_elem).transpose()\n",
    "    \n",
    "    exp = np.exp(diff)\n",
    "    sum_exp=np.sum(exp, axis=1)\n",
    "    probs = (exp.transpose() / sum_exp).transpose()  #b,a / a .trns\n",
    "    #print(\"probs\",probs)\n",
    "    #print(\"x\",x)\n",
    "    \"\"\"\n",
    "    for i in range(probs.shape[0]):\n",
    "        for j in range(probs.shape[1]):\n",
    "            if probs[i,j]<1e-9:\n",
    "                probs[i,j]=1e-9\n",
    "    #print(\"after\",probs)\n",
    "       \"\"\"     \n",
    "    return probs\n",
    "\"\"\"\n",
    "def softmax_(x):\n",
    "    x=x-np.max(x)\n",
    "    exp_=np.exp(x)\n",
    "    sum_=np.sum(x,axis=1)\n",
    "    return exp_/sum_\n",
    "\n",
    "def softmax_derv(x):\n",
    "    derv_ = softmax_(x)*(1-softmax_(x))\n",
    "    sum_=np.sum(x,axis=1)\n",
    "    exp_=np.exp(x)\n",
    "    return exp_/sum_\n",
    "\"\"\"\n",
    "\n",
    "def softmax_derv(x):\n",
    "    if len(x.shape)!=2:\n",
    "        raise Exception(\"소프트맥스역전파에러\")\n",
    "    #print(x.shape)\n",
    "    temp_batch_size=x.shape[0]\n",
    "    temp_output_size=x.shape[1]\n",
    "    x_temp=np.zeros((temp_batch_size,temp_output_size,temp_output_size), dtype='float32')\n",
    "    x_temp_after=np.zeros((temp_batch_size,temp_output_size,temp_output_size), dtype='float32')\n",
    "    for i in range(temp_batch_size):\n",
    "        x_temp[i,:,:]=np.diag(x[i,:])\n",
    "        #print(x[i,:].reshape(x.shape[1],1).shape)\n",
    "        temp=np.tile(x[i,:].reshape(x.shape[1],1),x.shape[1])\n",
    "        #print(temp.shape)\n",
    "        x_temp_after[i,:,:]=temp*np.transpose(temp)\n",
    "        x_temp[i,:,:] = x_temp[i,:,:]-x_temp_after[i,:,:]\n",
    "        \n",
    "    \n",
    "    #https://aimatters.wordpress.com/2019/06/17/the-softmax-function-derivative/\n",
    "    return np.sum(x_temp,axis=1)\n",
    "\"\"\"\n",
    "def softmax_derv(x,y):\n",
    "    mb_size, nom_size = x.shape\n",
    "    derv = np.ndarray([mb_size,nom_size,nom_size])\n",
    "    for n in range(mb_size):\n",
    "        for i in range(nom_size):\n",
    "            for j in range(nom_size):\n",
    "                derv[n,i,j]=-y[n,i]*y[n,j]\n",
    "            derv[n,i,i]+=y[n,i]\n",
    "    return derv\n",
    "    \"\"\"\n",
    "def softmax_cross_entropy_with_logits(labels, logits):\n",
    "    probs = softmax(logits)\n",
    "    #print(labels.shape)\n",
    "    #print(logits.shape,\"d\")\n",
    "    #print(\"logis\",logits)\n",
    "    #print(\"prob\",probs)\n",
    "    \n",
    "    return -np.sum(labels * np.log(probs+1.0e-10), axis=1)\n",
    "\n",
    "def softmax_cross_entropy_with_logits_derv(labels, logits):\n",
    "    return softmax(logits) - labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path, skip_header=True):\n",
    "    with open(path) as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        headers = None\n",
    "        if skip_header: headers = next(csvreader, None)\n",
    "        rows = []\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "            \n",
    "    return rows, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(xs, cnt):\n",
    "    return np.eye(cnt)[np.array(xs).astype(int)]\n",
    "\n",
    "def vector_to_str(x, fmt='%.2f', max_cnt=0):\n",
    "    if max_cnt == 0 or len(x) <= max_cnt:\n",
    "        return '[' + ','.join([fmt]*len(x)) % tuple(x) + ']'\n",
    "    v = x[0:max_cnt]\n",
    "    return '[' + ','.join([fmt]*len(v)) % tuple(v) + ',...]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_pixels(imagepath, resolution, input_shape):\n",
    "    img = Image.open(imagepath)\n",
    "    resized = img.resize(resolution)\n",
    "    return np.array(resized).reshape(input_shape)\n",
    "\n",
    "def draw_images_horz(xs, image_shape=None):\n",
    "    show_cnt = len(xs)\n",
    "    fig, axes = plt.subplots(1, show_cnt, figsize=(5,5))\n",
    "    for n in range(show_cnt):\n",
    "        img = xs[n]\n",
    "        if image_shape:\n",
    "            x3d = img.reshape(image_shape)\n",
    "            img = Image.fromarray(np.uint8(x3d))\n",
    "        axes[n].imshow(img)\n",
    "        axes[n].axis('off')\n",
    "    plt.draw()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_select_results(est, ans, target_names, max_cnt=0):\n",
    "    for n in range(len(est)):\n",
    "        pstr = vector_to_str(100*est[n], '%2.0f', max_cnt)\n",
    "        estr = target_names[np.argmax(est[n])]\n",
    "        astr = target_names[np.argmax(ans[n])]\n",
    "        rstr = 'O'\n",
    "        if estr != astr: rstr = 'X'\n",
    "        print('추정확률분포 {} => 추정 {} : 정답 {} => {}'. \\\n",
    "              format(pstr, estr, astr, rstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dir(path):\n",
    "    filenames = os.listdir(path)\n",
    "    filenames.sort()\n",
    "    return filenames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
